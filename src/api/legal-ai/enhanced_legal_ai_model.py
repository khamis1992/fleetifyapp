#!/usr/bin/env python3
"""
Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ
ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¬ÙŠ
"""

import os
import json
import time
import hashlib
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
import logging
from openai import OpenAI

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…Ø·ÙˆØ±Ø©
from smart_caching_system import SmartCachingSystem
from local_knowledge_base import LocalKnowledgeBase
from adaptive_learning_system import AdaptiveLearningSystem, UserFeedback

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnhancedLegalAIModel:
    """Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ"""
    
    def __init__(self):
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_API_BASE", "https://api.manus.im/api/llm-proxy/v1")
        )
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø°ÙƒÙŠØ©
        self.cache_system = SmartCachingSystem()
        self.knowledge_base = LocalKnowledgeBase()
        self.learning_system = AdaptiveLearningSystem()
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        self.performance_stats = {
            'total_queries': 0,
            'cache_hits': 0,
            'local_knowledge_hits': 0,
            'api_calls': 0,
            'total_cost_saved': 0.0,
            'average_response_time': 0.0,
            'user_satisfaction': 0.0
        }
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        self.legal_knowledge = self._load_legal_knowledge()
        
        logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ø¨Ù†Ø¬Ø§Ø­")
    
    def _load_legal_knowledge(self) -> Dict[str, Any]:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
        return {
            'saudi_arabia': {
                'name': 'Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©',
                'laws': [
                    'Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯',
                    'Ù„Ø§Ø¦Ø­Ø© ØªØ£Ø¬ÙŠØ± Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª ÙˆÙˆØ³Ø·Ø§Ø¡ Ø§Ù„ØªØ£Ø¬ÙŠØ±',
                    'Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ'
                ],
                'authorities': [
                    'Ø§Ù„Ù‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ù†Ù‚Ù„',
                    'ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØªØ¬Ø§Ø±Ø©',
                    'ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© (Ø§Ù„Ù…Ø±ÙˆØ±)'
                ]
            },
            'qatar': {
                'name': 'Ø¯ÙˆÙ„Ø© Ù‚Ø·Ø±',
                'laws': [
                    'Ù…Ø±Ø³ÙˆÙ… Ø¨Ù‚Ø§Ù†ÙˆÙ† Ø±Ù‚Ù… (19) Ù„Ø³Ù†Ø© 2007 ÙÙŠ Ø´Ø£Ù† Ø§Ù„Ù…Ø±ÙˆØ±',
                    'Ù‚Ø±Ø§Ø± ÙˆØ²ÙŠØ± Ø§Ù„Ù…ÙˆØ§ØµÙ„Ø§Øª Ø±Ù‚Ù… (13) Ù„Ø³Ù†Ø© 2024 Ø¨Ø´Ø£Ù† Ø§Ù„Ù„ÙŠÙ…ÙˆØ²ÙŠÙ†'
                ],
                'authorities': [
                    'ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ù…ÙˆØ§ØµÙ„Ø§Øª ÙˆØ§Ù„Ø§ØªØµØ§Ù„Ø§Øª',
                    'ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©',
                    'ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØªØ¬Ø§Ø±Ø© ÙˆØ§Ù„ØµÙ†Ø§Ø¹Ø©'
                ]
            },
            'kuwait': {
                'name': 'Ø¯ÙˆÙ„Ø© Ø§Ù„ÙƒÙˆÙŠØª',
                'laws': [
                    'Ù…Ø±Ø³ÙˆÙ… Ø¨Ù‚Ø§Ù†ÙˆÙ† Ø±Ù‚Ù… 67 Ù„Ø³Ù†Ø© 1976 ÙÙŠ Ø´Ø£Ù† Ø§Ù„Ù…Ø±ÙˆØ±',
                    'Ù…Ø±Ø³ÙˆÙ… Ø¨Ù‚Ø§Ù†ÙˆÙ† Ø±Ù‚Ù… 5 Ù„Ø³Ù†Ø© 2025 (Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©)'
                ],
                'authorities': [
                    'ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© (Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ù…Ø±ÙˆØ±)',
                    'ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØªØ¬Ø§Ø±Ø© ÙˆØ§Ù„ØµÙ†Ø§Ø¹Ø©',
                    'Ø¨Ù„Ø¯ÙŠØ© Ø§Ù„ÙƒÙˆÙŠØª'
                ]
            }
        }
    
    def generate_legal_advice(self, query: str, country: str = 'saudi_arabia') -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ´Ø§Ø±Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ø­Ø³Ù†"""
        start_time = time.time()
        self.performance_stats['total_queries'] += 1
        
        try:
            # ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø£ÙˆÙ„Ø§Ù‹
            query_type = self._classify_query_type(query)
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠØ©
            if query_type == 'system_data':
                return self._handle_system_data_query(query, country, start_time)
            
            # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            cached_result = self.cache_system.check_cache(query, country)
            if cached_result:
                self.performance_stats['cache_hits'] += 1
                response_time = time.time() - start_time
                
                return {
                    'advice': cached_result['response'],
                    'source': 'cache',
                    'confidence': cached_result['confidence_score'],
                    'response_time': response_time,
                    'cost_saved': True,
                    'usage_count': cached_result['usage_count'],
                    'metadata': {
                        'source': 'cache',
                        'query_type': query_type,
                        'confidence': cached_result['confidence_score'],
                        'response_time': response_time,
                        'cost_saved': True,
                        'usage_count': cached_result['usage_count']
                    }
                }
            
            # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ©
            local_result = self.knowledge_base.search_knowledge(query, country)
            if local_result:
                self.performance_stats['local_knowledge_hits'] += 1
                response_time = time.time() - start_time
                
                # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ù„Ù„Ù…Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
                self.cache_system.store_response(
                    query, local_result['answer'], country, 
                    confidence_score=local_result['confidence']
                )
                
                return {
                    'advice': local_result['answer'],
                    'source': 'local_knowledge',
                    'confidence': local_result['confidence'],
                    'response_time': response_time,
                    'cost_saved': True,
                    'match_score': local_result['match_score'],
                    'metadata': {
                        'source': 'local_knowledge',
                        'query_type': query_type,
                        'confidence': local_result['confidence'],
                        'response_time': response_time,
                        'cost_saved': True,
                        'match_score': local_result['match_score']
                    }
                }
            
            # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API Ù…Ø¹ prompt Ù…Ø­Ø³Ù†
            self.performance_stats['api_calls'] += 1
            api_result = self._call_api_with_optimized_prompt(query, country)
            response_time = time.time() - start_time
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø°ÙƒÙŠØ©
            self.cache_system.store_response(
                query, api_result['advice'], country, 
                confidence_score=api_result['confidence']
            )
            
            self.cache_system.learn_from_query(query, api_result['advice'], country)
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            self._update_performance_stats(response_time, api_result.get('cost', 0.0))
            
            return {
                **api_result,
                'source': 'api',
                'response_time': response_time,
                'metadata': {
                    'source': 'api',
                    'query_type': query_type,
                    'confidence': api_result['confidence'],
                    'response_time': response_time,
                    'cost_saved': False
                }
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©: {e}")
            return {
                'advice': 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',
                'source': 'error',
                'confidence': 0.0,
                'response_time': time.time() - start_time,
                'error': str(e)
            }
    
    def _handle_system_data_query(self, query: str, country: str, start_time: float) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬ Ø®Ø§Øµ Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠØ©"""
        try:
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            data_query = self._parse_system_data_query(query)
            
            if data_query:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù…
                system_data = self._fetch_system_data(data_query, country)
                
                if system_data:
                    response_time = time.time() - start_time
                    
                    # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
                    formatted_response = self._format_system_data_response(data_query, system_data)
                    
                    return {
                        'advice': formatted_response,
                        'system_data': system_data,
                        'source': 'system_data',
                        'confidence': 0.95,
                        'response_time': response_time,
                        'cost_saved': True,
                        'classification': {
                            'type': 'system_data',
                            'confidence': 0.95,
                            'reasoning': 'ØªÙ… ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± ÙƒØ·Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø¸Ø§Ù…ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©'
                        },
                        'metadata': {
                            'source': 'system_data',
                            'query_type': 'system_data',
                            'confidence': 0.95,
                            'response_time': response_time,
                            'cost_saved': True,
                            'data_sources': ['database']
                        }
                    }
            
            # Ø¥Ø°Ø§ Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± ÙƒØ¨ÙŠØ§Ù†Ø§Øª Ù†Ø¸Ø§Ù…ÙŠØ©ØŒ Ù†Ø±Ø¬Ø¹ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø§Ø¯ÙŠØ©
            return self._fallback_to_ai_processing(query, country, start_time)
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªÙØ³Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠØ©: {e}")
            return self._fallback_to_ai_processing(query, country, start_time)
    
    def _parse_system_data_query(self, query: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªÙØ³Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠØ©"""
        query_lower = query.lower()
        
        # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        patterns = {
            'contract_count': {
                'keywords': ['ÙƒÙ… Ø¹Ù‚Ø¯', 'Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù‚ÙˆØ¯'],
                'statuses': {
                    'Ù…Ù„ØºÙŠ': 'cancelled',
                    'Ù†Ø´Ø·': 'active', 
                    'Ù…Ù†ØªÙ‡ÙŠ': 'expired',
                    'Ù…Ø¹Ù„Ù‚': 'suspended',
                    'Ù…ÙƒØªÙ…Ù„': 'completed'
                }
            },
            'customer_count': {
                'keywords': ['ÙƒÙ… Ø¹Ù…ÙŠÙ„', 'Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡'],
                'types': {
                    'Ø£ÙØ±Ø§Ø¯': 'individual',
                    'Ø´Ø±ÙƒØ§Øª': 'corporate'
                }
            },
            'vehicle_count': {
                'keywords': ['ÙƒÙ… Ù…Ø±ÙƒØ¨Ø©', 'ÙƒÙ… Ø³ÙŠØ§Ø±Ø©', 'Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª', 'Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª'],
                'statuses': {
                    'Ù…ØªØ§Ø­Ø©': 'available',
                    'Ù…Ø¤Ø¬Ø±Ø©': 'rented',
                    'ØµÙŠØ§Ù†Ø©': 'maintenance'
                }
            }
        }
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±
        for query_type, config in patterns.items():
            if any(keyword in query_lower for keyword in config['keywords']):
                result = {
                    'type': query_type,
                    'table': self._get_table_name(query_type),
                    'filters': {}
                }
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙÙ„Ø§ØªØ± ÙÙŠ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±
                if 'statuses' in config:
                    for arabic_status, english_status in config['statuses'].items():
                        if arabic_status in query_lower:
                            result['filters']['status'] = english_status
                            break
                
                if 'types' in config:
                    for arabic_type, english_type in config['types'].items():
                        if arabic_type in query_lower:
                            result['filters']['type'] = english_type
                            break
                
                return result
        
        return None
    
    def _get_table_name(self, query_type: str) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±"""
        table_mapping = {
            'contract_count': 'contracts',
            'customer_count': 'customers', 
            'vehicle_count': 'vehicles'
        }
        return table_mapping.get(query_type, 'unknown')
    
    def _fetch_system_data(self, data_query: Dict[str, Any], country: str) -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù… (Ù…Ø­Ø§ÙƒØ§Ø© - ÙŠØ¬Ø¨ ØªØ·ÙˆÙŠØ±Ù‡Ø§ Ù„Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©)"""
        try:
            # Ù‡Ø°Ù‡ Ù…Ø­Ø§ÙƒØ§Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª - ÙŠØ¬Ø¨ Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡Ø§ Ø¨Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„ÙØ¹Ù„ÙŠ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            mock_data = {
                'contracts': {
                    'total': 150,
                    'active': 85,
                    'cancelled': 25,
                    'expired': 30,
                    'suspended': 10
                },
                'customers': {
                    'total': 120,
                    'individual': 80,
                    'corporate': 40
                },
                'vehicles': {
                    'total': 75,
                    'available': 25,
                    'rented': 45,
                    'maintenance': 5
                }
            }
            
            table = data_query.get('table', '')
            if table in mock_data:
                result = {'total_count': mock_data[table]['total']}
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
                filters = data_query.get('filters', {})
                if 'status' in filters:
                    status = filters['status']
                    if status in mock_data[table]:
                        result['filtered_count'] = mock_data[table][status]
                        result['filter_applied'] = status
                
                if 'type' in filters:
                    type_filter = filters['type']
                    if type_filter in mock_data[table]:
                        result['filtered_count'] = mock_data[table][type_filter]
                        result['filter_applied'] = type_filter
                
                result['data_source'] = 'database_simulation'
                return result
            
            return None
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠØ©: {e}")
            return None
    
    def _format_system_data_response(self, data_query: Dict[str, Any], system_data: Dict[str, Any]) -> str:
        """ØªÙ†Ø³ÙŠÙ‚ Ø±Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠØ©"""
        try:
            query_type = data_query.get('type', '')
            table = data_query.get('table', '')
            filters = data_query.get('filters', {})
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ø³Ù… Ø§Ù„ÙƒÙŠØ§Ù† Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            entity_names = {
                'contracts': 'Ø§Ù„Ø¹Ù‚ÙˆØ¯',
                'customers': 'Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡',
                'vehicles': 'Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª'
            }
            entity_name = entity_names.get(table, 'Ø§Ù„Ø¹Ù†Ø§ØµØ±')
            
            # ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„ÙÙ„ØªØ± Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            status_names = {
                'active': 'Ø§Ù„Ù†Ø´Ø·Ø©',
                'cancelled': 'Ø§Ù„Ù…Ù„ØºÙŠØ©',
                'expired': 'Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ©',
                'suspended': 'Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©',
                'individual': 'Ø§Ù„Ø£ÙØ±Ø§Ø¯',
                'corporate': 'Ø§Ù„Ø´Ø±ÙƒØ§Øª',
                'available': 'Ø§Ù„Ù…ØªØ§Ø­Ø©',
                'rented': 'Ø§Ù„Ù…Ø¤Ø¬Ø±Ø©',
                'maintenance': 'ÙÙŠ Ø§Ù„ØµÙŠØ§Ù†Ø©'
            }
            
            if 'filtered_count' in system_data:
                filter_applied = system_data.get('filter_applied', '')
                status_arabic = status_names.get(filter_applied, filter_applied)
                
                response = f"Ø¹Ø¯Ø¯ {entity_name} {status_arabic}: {system_data['filtered_count']}\n"
                response += f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ {entity_name}: {system_data['total_count']}\n\n"
                
                # Ø¥Ø¶Ø§ÙØ© Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©
                if system_data['total_count'] > 0:
                    percentage = (system_data['filtered_count'] / system_data['total_count']) * 100
                    response += f"Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©: {percentage:.1f}%\n\n"
            else:
                response = f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ {entity_name}: {system_data['total_count']}\n\n"
            
            response += "ğŸ“Š Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø£Ø®ÙˆØ°Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø³Ø·ÙˆÙ„"
            
            return response
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø±Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            return f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: {system_data}"
    
    def _fallback_to_ai_processing(self, query: str, country: str, start_time: float) -> Dict[str, Any]:
        """Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        try:
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API Ù…Ø¹ prompt Ù…Ø­Ø³Ù† Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©
            api_result = self._call_api_with_mixed_query_prompt(query, country)
            response_time = time.time() - start_time
            
            return {
                **api_result,
                'source': 'mixed_query_ai',
                'response_time': response_time,
                'classification': {
                    'type': 'mixed',
                    'confidence': 0.7,
                    'reasoning': 'ØªÙ… ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± ÙƒØ§Ø³ØªÙØ³Ø§Ø± Ù…Ø®ØªÙ„Ø· ÙŠØªØ·Ù„Ø¨ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ'
                },
                'metadata': {
                    'source': 'mixed_query_ai',
                    'query_type': 'mixed',
                    'confidence': api_result.get('confidence', 0.8),
                    'response_time': response_time,
                    'cost_saved': False
                }
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
            return {
                'advice': 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',
                'source': 'error',
                'confidence': 0.0,
                'response_time': time.time() - start_time,
                'error': str(e)
            }
    
    def _call_api_with_mixed_query_prompt(self, query: str, country: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API Ù…Ø¹ prompt Ù…Ø­Ø³Ù† Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©"""
        country_info = self.legal_knowledge.get(country, {})
        
        system_prompt = f"""Ø£Ù†Øª Ù…Ø­Ø§Ù…ÙŠ Ø®Ø¨ÙŠØ± ÙˆÙ…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ®ØµØµ ÙÙŠ Ù‚ÙˆØ§Ù†ÙŠÙ† {country_info.get('name', country)} ÙˆÙ†Ø¸Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø³Ø·ÙˆÙ„.

Ø®Ø¨Ø±ØªÙƒ ØªØ´Ù…Ù„:
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙˆØ§Ù„ØªØ´ØºÙŠÙ„ÙŠØ©
- Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…Ø±ÙˆØ± ÙˆØªØ£Ø¬ÙŠØ± Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª  
- ØªÙØ³ÙŠØ± Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
- Ø±Ø¨Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©

Ø¹Ù†Ø¯ Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
1. Ù‚Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ø¨ÙˆØ¶ÙˆØ­
2. Ø§Ø±Ø¨Ø·Ù‡Ø§ Ø¨Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
3. Ù‚Ø¯Ù… Ù†ØµØ§Ø¦Ø­ Ø¹Ù…Ù„ÙŠØ© Ù„Ù„ØªØ­Ø³ÙŠÙ†
4. Ø§Ø°ÙƒØ± Ø£ÙŠ Ø§Ø¹ØªØ¨Ø§Ø±Ø§Øª Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ù‡Ù…Ø©"""
        
        user_prompt = f"""
Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±: {query}

ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø© ØªØªØ¶Ù…Ù†:
- ØªØ­Ù„ÙŠÙ„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
- Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
- Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            advice = response.choices[0].message.content
            
            return {
                'advice': advice,
                'confidence': 0.85,
                'source': 'mixed_query_ai'
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø§Ù„Ù…Ø®ØªÙ„Ø·: {e}")
            raise
    
    def _call_api_with_optimized_prompt(self, query: str, country: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API Ù…Ø¹ prompt Ù…Ø­Ø³Ù†"""
        
        # Ø¥Ù†Ø´Ø§Ø¡ prompt Ù…Ø­Ø³Ù† ÙˆÙ…Ø®ØªØµØ±
        system_prompt = self._create_optimized_system_prompt(country)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ ÙÙ‚Ø·
        relevant_context = self._get_relevant_context(query, country)
        
        user_prompt = f"""
Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ: {relevant_context}

Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±: {query}

ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø§Ø³ØªØ´Ø§Ø±Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…ÙØµÙ„Ø© ÙˆØ¯Ù‚ÙŠÙ‚Ø©.
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            advice = response.choices[0].message.content
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ©
            input_tokens = len(system_prompt.split()) + len(user_prompt.split())
            output_tokens = len(advice.split())
            cost = self._calculate_cost(input_tokens, output_tokens)
            
            return {
                'advice': advice,
                'confidence': 0.9,  # Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ù…Ù† API
                'cost': cost,
                'tokens_used': input_tokens + output_tokens
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API: {e}")
            raise
    
    def _create_optimized_system_prompt(self, country: str) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ prompt Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†"""
        country_info = self.legal_knowledge.get(country, {})
        
        return f"""Ø£Ù†Øª Ù…Ø­Ø§Ù…ÙŠ Ø®Ø¨ÙŠØ± Ù…ØªØ®ØµØµ ÙÙŠ Ù‚ÙˆØ§Ù†ÙŠÙ† {country_info.get('name', country)} ÙÙŠ Ù…Ø¬Ø§Ù„ ØªØ£Ø¬ÙŠØ± Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª ÙˆØ§Ù„Ù„ÙŠÙ…ÙˆØ²ÙŠÙ†.

Ø®Ø¨Ø±ØªÙƒ ØªØ´Ù…Ù„:
- Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…Ø±ÙˆØ± ÙˆØ§Ù„Ù†Ù‚Ù„
- Ø£Ù†Ø¸Ù…Ø© ØªØ£Ø¬ÙŠØ± Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª
- Ø§Ù„ØªØ±Ø§Ø®ÙŠØµ Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©
- Ø§Ù„Ø¹Ù‚ÙˆØ¯ ÙˆØ§Ù„Ù…Ø°ÙƒØ±Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©

Ù‚Ø¯Ù… Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙØµÙ„Ø© Ù…Ø¹ Ø°ÙƒØ± Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù…ÙƒØ§Ù†.
Ø§Ø¬Ø¹Ù„ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ Ø¹Ù…Ù„ÙŠØ© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚."""
    
    def _get_relevant_context(self, query: str, country: str) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø±"""
        country_info = self.legal_knowledge.get(country, {})
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['Ø´Ø±ÙˆØ·', 'ØªØ£Ø³ÙŠØ³', 'Ø´Ø±ÙƒØ©']):
            context = f"Ù‚ÙˆØ§Ù†ÙŠÙ† ØªØ£Ø³ÙŠØ³ Ø§Ù„Ø´Ø±ÙƒØ§Øª ÙÙŠ {country_info.get('name')}"
        elif any(word in query_lower for word in ['ØªØ±Ø®ÙŠØµ', 'Ù„ÙŠÙ…ÙˆØ²ÙŠÙ†']):
            context = f"Ø£Ù†Ø¸Ù…Ø© ØªØ±Ø®ÙŠØµ Ø§Ù„Ù„ÙŠÙ…ÙˆØ²ÙŠÙ† ÙÙŠ {country_info.get('name')}"
        elif any(word in query_lower for word in ['Ø¹Ù‚ÙˆØ¨Ø§Øª', 'Ù…Ø±ÙˆØ±', 'ØºØ±Ø§Ù…Ø§Øª']):
            context = f"Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…Ø±ÙˆØ± ÙˆØ§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª ÙÙŠ {country_info.get('name')}"
        else:
            context = f"Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¹Ø§Ù…Ø© Ù„ØªØ£Ø¬ÙŠØ± Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª ÙÙŠ {country_info.get('name')}"
        
        return context
    
    def _calculate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """Ø­Ø³Ø§Ø¨ ØªÙƒÙ„ÙØ© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API"""
        # Ø£Ø³Ø¹Ø§Ø± GPT-4o-mini
        input_cost_per_1k = 0.00015  # $0.00015 per 1K input tokens
        output_cost_per_1k = 0.0006  # $0.0006 per 1K output tokens
        
        input_cost = (input_tokens / 1000) * input_cost_per_1k
        output_cost = (output_tokens / 1000) * output_cost_per_1k
        
        return input_cost + output_cost
    
    def _update_performance_stats(self, response_time: float, cost: float):
        """ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        # ØªØ­Ø¯ÙŠØ« Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
        total_queries = self.performance_stats['total_queries']
        current_avg = self.performance_stats['average_response_time']
        new_avg = ((current_avg * (total_queries - 1)) + response_time) / total_queries
        self.performance_stats['average_response_time'] = new_avg
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© (ØªÙ‚Ø¯ÙŠØ±)
        estimated_full_cost = cost * 3  # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ØªÙƒÙ„ÙØ© Ø¨Ø¯ÙˆÙ† ØªØ­Ø³ÙŠÙ†
        cost_saved = estimated_full_cost - cost
        self.performance_stats['total_cost_saved'] += cost_saved
    
    def record_user_feedback(self, query: str, country: str, rating: int, 
                           feedback_text: str = None, user_id: str = None) -> bool:
        """ØªØ³Ø¬ÙŠÙ„ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        try:
            query_hash = hashlib.md5(f"{query}_{country}".encode('utf-8')).hexdigest()
            
            feedback = UserFeedback(
                query_hash=query_hash,
                rating=rating,
                feedback_text=feedback_text,
                country=country,
                query_type=self._classify_query_type(query),
                timestamp=datetime.now(),
                user_id=user_id
            )
            
            success = self.learning_system.record_user_feedback(feedback)
            
            if success:
                # ØªØ­Ø¯ÙŠØ« Ù…ØªÙˆØ³Ø· Ø±Ø¶Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
                self._update_user_satisfaction(rating)
                
                # ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Ù‹
                if rating >= 4:
                    self._update_knowledge_from_feedback(query, country, rating)
            
            return success
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {e}")
            return False
    
    def _classify_query_type(self, query: str) -> str:
        """ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø§Ù„Ù…Ø­Ø³Ù†"""
        query_lower = query.lower()
        
        # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠØ©
        system_data_keywords = [
            'ÙƒÙ…', 'Ø¹Ø¯Ø¯', 'Ø¥Ø­ØµØ§Ø¦ÙŠØ©', 'Ù…Ø¬Ù…ÙˆØ¹', 'Ù…ØªÙˆØ³Ø·', 'Ø£Ø¹Ù„Ù‰', 'Ø£Ù‚Ù„',
            'Ù†Ø³Ø¨Ø©', 'Ù…Ø¹Ø¯Ù„', 'Ø¥Ø¬Ù…Ø§Ù„ÙŠ', 'ØªÙ‚Ø±ÙŠØ±', 'Ù‚Ø§Ø¦Ù…Ø©', 'Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
            'Ø­Ø§Ù„Ø©', 'ÙˆØ¶Ø¹', 'Ù…Ù„ØºÙŠ', 'Ù†Ø´Ø·', 'Ù…Ù†ØªÙ‡ÙŠ', 'Ù…ÙƒØªÙ…Ù„', 'Ù…Ø¹Ù„Ù‚'
        ]
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
        if any(word in query_lower for word in system_data_keywords):
            return 'system_data'
        
        # Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        elif any(word in query_lower for word in ['Ø§Ø³ØªØ´Ø§Ø±Ø©', 'Ø³Ø¤Ø§Ù„', 'Ù…Ø§ Ù‡ÙŠ', 'ÙƒÙŠÙ', 'Ù…Ø§Ø°Ø§']):
            return 'consultation'
        
        # Ø§Ù„Ù…Ø°ÙƒØ±Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        elif any(word in query_lower for word in ['Ù…Ø°ÙƒØ±Ø©', 'Ø¯ÙØ§Ø¹', 'Ù…Ø±Ø§ÙØ¹Ø©']):
            return 'memo'
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù‚ÙˆØ¯
        elif any(word in query_lower for word in ['Ø¹Ù‚Ø¯', 'ØªØ­Ù„ÙŠÙ„', 'Ù…Ø±Ø§Ø¬Ø¹Ø©']):
            return 'contract'
        
        # Ø§Ù„ØªØ±Ø§Ø®ÙŠØµ ÙˆØ§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª
        elif any(word in query_lower for word in ['ØªØ±Ø®ÙŠØµ', 'Ù…ØªØ·Ù„Ø¨Ø§Øª', 'Ø´Ø±ÙˆØ·']):
            return 'licensing'
        
        else:
            return 'general'
    
    def _update_user_satisfaction(self, rating: int):
        """ØªØ­Ø¯ÙŠØ« Ù…ØªÙˆØ³Ø· Ø±Ø¶Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"""
        current_satisfaction = self.performance_stats['user_satisfaction']
        total_queries = self.performance_stats['total_queries']
        
        if total_queries == 1:
            self.performance_stats['user_satisfaction'] = rating / 5.0
        else:
            new_satisfaction = ((current_satisfaction * (total_queries - 1)) + (rating / 5.0)) / total_queries
            self.performance_stats['user_satisfaction'] = new_satisfaction
    
    def _update_knowledge_from_feedback(self, query: str, country: str, rating: int):
        """ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ù† Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©"""
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
        cached_result = self.cache_system.check_cache(query, country)
        
        if cached_result and rating >= 4:
            # ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ©
            cache_entries = [{
                'original_query': query,
                'response': cached_result['response'],
                'country': country,
                'query_type': self._classify_query_type(query),
                'usage_count': cached_result['usage_count'],
                'confidence_score': 0.9,  # Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ù„Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©
                'query_hash': cached_result['query_hash']
            }]
            
            self.knowledge_base.update_from_cache(cache_entries)
    
    def get_comprehensive_stats(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ù†Ø¸Ø§Ù…"""
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
        cache_stats = self.cache_system.get_cache_stats()
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
        knowledge_stats = self.knowledge_base.get_knowledge_stats()
        
        # Ø±Ø¤Ù‰ Ø§Ù„ØªØ¹Ù„Ù…
        learning_insights = self.learning_system.get_learning_insights()
        
        # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„ÙƒÙØ§Ø¡Ø©
        total_queries = self.performance_stats['total_queries']
        if total_queries > 0:
            cache_hit_rate = (self.performance_stats['cache_hits'] / total_queries) * 100
            local_hit_rate = (self.performance_stats['local_knowledge_hits'] / total_queries) * 100
            api_usage_rate = (self.performance_stats['api_calls'] / total_queries) * 100
            cost_efficiency = (1 - (self.performance_stats['api_calls'] / total_queries)) * 100
        else:
            cache_hit_rate = local_hit_rate = api_usage_rate = cost_efficiency = 0
        
        return {
            'performance_overview': {
                'total_queries': total_queries,
                'cache_hit_rate': round(cache_hit_rate, 1),
                'local_knowledge_hit_rate': round(local_hit_rate, 1),
                'api_usage_rate': round(api_usage_rate, 1),
                'cost_efficiency': round(cost_efficiency, 1),
                'average_response_time': round(self.performance_stats['average_response_time'], 2),
                'user_satisfaction': round(self.performance_stats['user_satisfaction'] * 100, 1),
                'total_cost_saved': round(self.performance_stats['total_cost_saved'], 4)
            },
            'cache_system': cache_stats,
            'knowledge_base': knowledge_stats,
            'learning_system': learning_insights,
            'efficiency_breakdown': {
                'instant_responses': cache_stats['total_entries'],
                'local_responses': knowledge_stats['total_entries'],
                'api_calls_saved': cache_stats['total_usage'] + knowledge_stats.get('total_usage', 0),
                'estimated_monthly_savings': round(self.performance_stats['total_cost_saved'] * 30, 2)
            }
        }
    
    def optimize_system(self) -> Dict[str, Any]:
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ±Ø§ÙƒÙ…Ø©"""
        optimization_results = {
            'cache_cleanup': {},
            'knowledge_updates': {},
            'learning_improvements': {},
            'performance_gains': {}
        }
        
        try:
            # 1. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            cleanup_result = self.cache_system.cleanup_old_entries()
            optimization_results['cache_cleanup'] = cleanup_result
            
            # 2. ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            # Ø¬Ù„Ø¨ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            high_quality_entries = []  # ÙŠÙ…ÙƒÙ† ØªØ·ÙˆÙŠØ± Ù‡Ø°Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹
            knowledge_updates = self.knowledge_base.update_from_cache(high_quality_entries)
            optimization_results['knowledge_updates'] = {'new_entries': knowledge_updates}
            
            # 3. ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„ØªØ¹Ù„Ù…
            suggestions = self.learning_system.get_improvement_suggestions()
            optimization_results['learning_improvements'] = {
                'suggestions_count': len(suggestions),
                'high_priority_suggestions': [s for s in suggestions if s['priority'] == 'high']
            }
            
            # 4. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙƒØ§Ø³Ø¨ ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡
            stats = self.get_comprehensive_stats()
            optimization_results['performance_gains'] = {
                'cost_efficiency': stats['performance_overview']['cost_efficiency'],
                'response_efficiency': stats['performance_overview']['cache_hit_rate'] + stats['performance_overview']['local_knowledge_hit_rate'],
                'user_satisfaction': stats['performance_overview']['user_satisfaction']
            }
            
            logger.info("ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­")
            return optimization_results
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ø¸Ø§Ù…: {e}")
            return optimization_results
    
    def export_system_data(self, export_dir: str = "/home/ubuntu/system_export"):
        """ØªØµØ¯ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        try:
            os.makedirs(export_dir, exist_ok=True)
            
            # ØªØµØ¯ÙŠØ± Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø´Ø§Ù…Ù„Ø©
            stats = self.get_comprehensive_stats()
            with open(f"{export_dir}/comprehensive_stats.json", 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2)
            
            # ØªØµØ¯ÙŠØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
            self.knowledge_base._save_knowledge()
            
            # ØªØµØ¯ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¹Ù„Ù…
            self.learning_system.export_learning_data(f"{export_dir}/learning_data.json")
            
            # ØªØµØ¯ÙŠØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªØ±Ø§ÙƒÙ…Ø©
            self.cache_system.export_knowledge_base(f"{export_dir}/accumulated_knowledge.json")
            
            logger.info(f"ØªÙ… ØªØµØ¯ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø¥Ù„Ù‰ {export_dir}")
            return True
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØµØ¯ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…: {e}")
            return False

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù†
    enhanced_model = EnhancedLegalAIModel()
    
    # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ø³ØªÙØ³Ø§Ø±
    query = "Ù…Ø§ Ù‡ÙŠ Ø´Ø±ÙˆØ· ØªØ£Ø³ÙŠØ³ Ø´Ø±ÙƒØ© ØªØ£Ø¬ÙŠØ± Ø³ÙŠØ§Ø±Ø§Øª ÙÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©ØŸ"
    country = "saudi_arabia"
    
    print("Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±...")
    result = enhanced_model.generate_legal_advice(query, country)
    
    print(f"Ø§Ù„Ù…ØµØ¯Ø±: {result['source']}")
    print(f"ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {result['response_time']:.2f} Ø«Ø§Ù†ÙŠØ©")
    print(f"Ø§Ù„Ø«Ù‚Ø©: {result['confidence']:.2f}")
    print(f"Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {result['advice'][:200]}...")
    
    # ØªØ³Ø¬ÙŠÙ„ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    enhanced_model.record_user_feedback(query, country, 4, "Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙÙŠØ¯Ø© ÙˆÙˆØ§Ø¶Ø­Ø©")
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    stats = enhanced_model.get_comprehensive_stats()
    print(f"\nØ¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡:")
    print(f"Ù…Ø¹Ø¯Ù„ Ø§Ù„ÙƒÙØ§Ø¡Ø©: {stats['performance_overview']['cost_efficiency']:.1f}%")
    print(f"Ø±Ø¶Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†: {stats['performance_overview']['user_satisfaction']:.1f}%")
    print(f"Ø§Ù„ØªÙˆÙÙŠØ± ÙÙŠ Ø§Ù„ØªÙƒÙ„ÙØ©: ${stats['performance_overview']['total_cost_saved']:.4f}")

