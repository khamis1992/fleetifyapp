import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

const openAIApiKey = Deno.env.get('OPENAI_API_KEY');

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const supabaseClient = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_ANON_KEY') ?? ''
    );

    const { query, context, sessionId, companyId, userId } = await req.json();
    
    console.log('üß† Self-Learning AI Processing:', { query, context, sessionId, companyId });

    // Check for anti-loop mechanism: detect recent clarification requests for similar queries
    const recentClarifications = await supabaseClient
      .from('ai_clarification_sessions')
      .select('*')
      .eq('company_id', companyId)
      .gte('created_at', new Date(Date.now() - 5 * 60 * 1000).toISOString()) // Last 5 minutes
      .eq('session_status', 'active')
      .order('created_at', { ascending: false })
      .limit(3);

    // Analyze conversation context to detect if user is answering a previous question
    const conversationContext = analyzeConversationContext(query, context);
    console.log('üí¨ Conversation context:', conversationContext);

    // Step 1: Analyze query against existing learning patterns
    const { data: existingPatterns } = await supabaseClient
      .from('ai_learning_patterns')
      .select('*')
      .eq('company_id', companyId)
      .eq('is_active', true)
      .order('success_rate', { ascending: false });

    console.log(`üìö Found ${existingPatterns?.length || 0} existing learning patterns`);

    // Step 2: Calculate similarity to existing patterns
    const queryEmbedding = await generateEmbedding(query);
    let bestMatch = null;
    let highestSimilarity = 0;

    if (existingPatterns && existingPatterns.length > 0) {
      for (const pattern of existingPatterns) {
        const patternData = pattern.pattern_data as any;
        if (patternData.query_embedding) {
          const similarity = cosineSimilarity(queryEmbedding, patternData.query_embedding);
          console.log(`üîç Pattern similarity: ${similarity} for pattern: ${pattern.pattern_type}`);
          
          if (similarity > highestSimilarity && similarity > 0.4) { // Lowered threshold
            highestSimilarity = similarity;
            bestMatch = pattern;
          }
        }
      }
    }

    // Step 2.5: Check for simple/clear queries that don't need clarification
    const isSimpleQuery = await isQuerySimpleAndClear(query);
    console.log(`üéØ Query is simple and clear: ${isSimpleQuery}`);

    // Step 2.6: Check if this is an answer to a previous question
    const isAnswerToPreviousQuestion = conversationContext.isAnswerToQuestion;
    console.log(`üí° Is answer to previous question: ${isAnswerToPreviousQuestion}`);

    // Step 3: Enhanced clarification decision with anti-loop protection
    let needsClarification = false;
    let clarificationReason = '';
    
    // Anti-loop mechanism: Don't ask for clarification if we recently did for similar queries
    const hasRecentClarification = recentClarifications.data && recentClarifications.data.length > 0;
    
    if (hasRecentClarification) {
      console.log('üö´ Skipping clarification due to recent clarification requests');
      needsClarification = false;
      clarificationReason = 'Recently asked for clarification, preventing loop';
    } else if (isAnswerToPreviousQuestion) {
      console.log('üí≠ User is answering a previous question, processing directly');
      needsClarification = false;
      clarificationReason = 'User is answering a previous question';
    } else if (isSimpleQuery) {
      console.log('‚úÖ Query is simple and clear, processing directly');
      needsClarification = false;
      clarificationReason = 'Query is simple and clear';
    } else if (existingPatterns && existingPatterns.length === 0) {
      // No patterns exist - only clarify if query is complex and unclear
      needsClarification = conversationContext.complexityScore > 0.7 && conversationContext.clarityScore < 0.4;
      clarificationReason = 'No patterns exist and query is complex/unclear';
    } else {
      // Patterns exist - only clarify if similarity is very low AND query is complex
      needsClarification = highestSimilarity < 0.2 && conversationContext.complexityScore > 0.7;
      clarificationReason = 'Low pattern similarity and high query complexity';
    }
    
    console.log(`ü§î Needs clarification: ${needsClarification}, similarity: ${highestSimilarity}, isSimple: ${isSimpleQuery}, reason: ${clarificationReason}`);

    if (needsClarification) {
      // Generate intelligent clarification questions
      const clarificationQuestions = await generateClarificationQuestions(query, context, existingPatterns);
      
      const { data: clarificationSession } = await supabaseClient
        .from('ai_clarification_sessions')
        .insert({
          company_id: companyId,
          original_query: query,
          clarification_questions: clarificationQuestions,
          session_status: 'active',
          created_by: userId
        })
        .select('*')
        .single();

      return new Response(JSON.stringify({
        type: 'clarification_needed',
        session: clarificationSession,
        confidence: highestSimilarity,
        reason: 'Query intent unclear, need clarification to learn better'
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Step 4: Process with high confidence
    let responseData;
    let processingType = 'new_learning';

    if (bestMatch) {
      console.log(`‚úÖ Using existing pattern: ${bestMatch.pattern_type} with confidence: ${highestSimilarity}`);
      processingType = 'pattern_match';
      
      // Update pattern usage
      await supabaseClient
        .from('ai_learning_patterns')
        .update({
          usage_count: bestMatch.usage_count + 1,
          last_used_at: new Date().toISOString()
        })
        .eq('id', bestMatch.id);

      responseData = await processWithPattern(query, bestMatch, context);
    } else {
      console.log('üÜï Creating new learning experience');
      responseData = await processNewQuery(query, context);
    }

    // Step 5: Record the interaction for learning
    const { data: intentRecord } = await supabaseClient
      .from('ai_query_intents')
      .insert({
        company_id: companyId,
        original_query: query,
        normalized_query: query.toLowerCase().trim(),
        intent_classification: responseData.intent || 'general_query',
        confidence_score: highestSimilarity,
        context_data: context,
        created_by: userId
      })
      .select('*')
      .single();

    console.log('üìù Recorded query intent:', intentRecord?.id);

    // Step 6: Self-evaluate and learn from this interaction
    await selfEvaluateAndLearn(
      supabaseClient,
      companyId,
      query,
      responseData,
      queryEmbedding,
      processingType,
      userId
    );

    return new Response(JSON.stringify({
      type: 'success',
      response: responseData.response,
      intent: responseData.intent,
      confidence: highestSimilarity,
      processingType,
      suggestions: await generateFollowUpSuggestions(query, responseData),
      queryIntentId: intentRecord?.id
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error) {
    console.error('‚ùå Self-Learning AI Error:', error);
    
    // Learn from errors
    try {
      const supabaseClient = createClient(
        Deno.env.get('SUPABASE_URL') ?? '',
        Deno.env.get('SUPABASE_ANON_KEY') ?? ''
      );
      
      await supabaseClient
        .from('ai_learning_patterns')
        .insert({
          company_id: 'system',
          pattern_type: 'error_pattern',
          pattern_data: {
            error: error.message,
            timestamp: new Date().toISOString(),
            context: 'self_learning_processing'
          },
          success_rate: 0,
          is_active: true
        });
    } catch (loggingError) {
      console.error('Failed to log error for learning:', loggingError);
    }

    return new Response(JSON.stringify({ 
      error: 'Self-learning processing failed',
      details: error.message 
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});

async function generateEmbedding(text: string): Promise<number[]> {
  try {
    const response = await fetch('https://api.openai.com/v1/embeddings', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openAIApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'text-embedding-3-small',
        input: text,
      }),
    });

    const data = await response.json();
    return data.data[0].embedding;
  } catch (error) {
    console.error('Embedding generation failed:', error);
    return [];
  }
}

function cosineSimilarity(vecA: number[], vecB: number[]): number {
  if (vecA.length !== vecB.length) return 0;
  
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;
  
  for (let i = 0; i < vecA.length; i++) {
    dotProduct += vecA[i] * vecB[i];
    normA += vecA[i] * vecA[i];
    normB += vecB[i] * vecB[i];
  }
  
  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}

async function generateClarificationQuestions(
  query: string,
  context: any,
  existingPatterns: any[]
): Promise<string[]> {
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${openAIApiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'gpt-4o-mini',
      messages: [
        {
          role: 'system',
          content: `You are an AI assistant that generates clarification questions to better understand user queries. 
          
          Based on the user's query and existing learning patterns, generate 2-3 specific clarification questions that will help determine the user's exact intent.
          
          Existing patterns: ${JSON.stringify(existingPatterns?.map(p => p.pattern_type) || [])}
          
          Return ONLY a JSON array of questions, no other text.`
        },
        {
          role: 'user',
          content: `Query: "${query}"\nContext: ${JSON.stringify(context)}\n\nGenerate clarification questions:`
        }
      ],
      temperature: 0.7,
    }),
  });

  const data = await response.json();
  try {
    return JSON.parse(data.choices[0].message.content);
  } catch {
    return [
      "What specific information are you looking for?",
      "Are you asking about data analysis or taking an action?",
      "What time period are you interested in?"
    ];
  }
}

async function processWithPattern(query: string, pattern: any, context: any) {
  const patternData = pattern.pattern_data as any;
  
  return {
    response: `Based on learned pattern "${pattern.pattern_type}", I can help you with: ${query}`,
    intent: pattern.pattern_type,
    confidence: 0.9,
    usedPattern: true
  };
}

async function processNewQuery(query: string, context: any) {
  // Enhanced keyword-based processing for common queries
  const normalizedQuery = query.toLowerCase().trim();
  const conversationHistory = context?.conversationHistory || [];
  
  // Check if this is a follow-up response to a previous AI question
  const lastAIMessage = getLastAIMessage(conversationHistory);
  const isFollowUpAnswer = checkIfAnswerToQuestion(normalizedQuery, conversationHistory);
  
  if (isFollowUpAnswer && lastAIMessage) {
    // Process follow-up answers based on context
    if (lastAIMessage.content.includes('ÿßŸÑÿπŸÇŸàÿØ ÿßŸÑŸÜÿ¥ÿ∑ÿ©') || lastAIMessage.content.includes('ÿ¨ŸÖŸäÿπ ÿßŸÑÿπŸÇŸàÿØ')) {
      // This is answering a contract count question
      if (normalizedQuery.includes('ÿ¨ŸÖŸäÿπ') || normalizedQuery.includes('ŸÉŸÑ')) {
        return {
          response: 'ÿ≠ÿ≥ŸÜÿßŸãÿå ÿ≥ÿ£ŸÇŸàŸÖ ÿ®ÿπÿ±ÿ∂ ÿ•ÿ¨ŸÖÿßŸÑŸä ÿπÿØÿØ ÿßŸÑÿπŸÇŸàÿØ ŸÅŸä ÿßŸÑŸÜÿ∏ÿßŸÖ. ŸÑŸÑŸàÿµŸàŸÑ ÿ•ŸÑŸâ Ÿáÿ∞Ÿá ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ÿå ÿ£ÿ≠ÿ™ÿßÿ¨ ŸÑŸÑÿßÿ™ÿµÿßŸÑ ÿ®ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™. ÿ≥Ÿäÿ™ŸÖ ÿπÿ±ÿ∂ ÿ¨ŸÖŸäÿπ ÿßŸÑÿπŸÇŸàÿØ ÿ®ŸÖÿß ŸÅŸä ÿ∞ŸÑŸÉ ÿßŸÑŸÜÿ¥ÿ∑ÿ© ŸàÿßŸÑŸÖŸÜÿ™ŸáŸäÿ© ÿßŸÑÿµŸÑÿßÿ≠Ÿäÿ©.',
          intent: 'contract_count_all',
          confidence: 0.9,
          usedPattern: false,
          adaptiveRecommendations: ['ÿπÿ±ÿ∂ ÿ™ŸÅÿßÿµŸäŸÑ ÿßŸÑÿπŸÇŸàÿØ', 'ÿ™ÿµŸÜŸäŸÅ ÿßŸÑÿπŸÇŸàÿØ ÿ≠ÿ≥ÿ® ÿßŸÑÿ≠ÿßŸÑÿ©', 'ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿ¥Ÿáÿ±Ÿäÿ© ŸÑŸÑÿπŸÇŸàÿØ']
        };
      } else if (normalizedQuery.includes('ŸÜÿ¥ÿ∑ÿ©') || normalizedQuery.includes('ÿßŸÑŸÜÿ¥ÿ∑ÿ©')) {
        return {
          response: 'ŸÖŸÖÿ™ÿßÿ≤ÿå ÿ≥ÿ£ÿπÿ±ÿ∂ ŸÑŸÉ ÿßŸÑÿπŸÇŸàÿØ ÿßŸÑŸÜÿ¥ÿ∑ÿ© ŸÅŸÇÿ∑. Ÿáÿ∞ÿß ÿ≥Ÿäÿ¥ŸÖŸÑ ÿßŸÑÿπŸÇŸàÿØ ÿßŸÑÿ™Ÿä ŸÑŸÖ ÿ™ŸÜÿ™Ÿá ÿµŸÑÿßÿ≠Ÿäÿ™Ÿáÿß ŸàŸÖÿß ÿ≤ÿßŸÑÿ™ ÿ≥ÿßÿ±Ÿäÿ© ÿßŸÑŸÖŸÅÿπŸàŸÑ.',
          intent: 'contract_count_active',
          confidence: 0.9,
          usedPattern: false,
          adaptiveRecommendations: ['ÿπÿ±ÿ∂ ÿ™ŸÅÿßÿµŸäŸÑ ÿßŸÑÿπŸÇŸàÿØ ÿßŸÑŸÜÿ¥ÿ∑ÿ©', 'ÿ™Ÿàÿßÿ±ŸäÿÆ ÿßŸÜÿ™Ÿáÿßÿ° ÿßŸÑÿπŸÇŸàÿØ', 'ÿßŸÑÿπŸÇŸàÿØ ÿßŸÑŸÇÿ±Ÿäÿ®ÿ© ŸÖŸÜ ÿßŸÑÿßŸÜÿ™Ÿáÿßÿ°']
        };
      }
    }
    
    if (lastAIMessage.content.includes('ÿßŸÑÿπŸÖŸÑÿßÿ° ÿßŸÑŸÜÿ¥ÿ∑ŸäŸÜ') || lastAIMessage.content.includes('ÿ¨ŸÖŸäÿπ ÿßŸÑÿπŸÖŸÑÿßÿ°')) {
      // This is answering a customer count question
      if (normalizedQuery.includes('ÿ¨ŸÖŸäÿπ') || normalizedQuery.includes('ŸÉŸÑ')) {
        return {
          response: 'ÿ≥ÿ£ÿπÿ±ÿ∂ ŸÑŸÉ ÿ•ÿ¨ŸÖÿßŸÑŸä ÿπÿØÿØ ÿßŸÑÿπŸÖŸÑÿßÿ° ÿßŸÑŸÖÿ≥ÿ¨ŸÑŸäŸÜ ŸÅŸä ÿßŸÑŸÜÿ∏ÿßŸÖÿå ÿ®ŸÖÿß ŸÅŸä ÿ∞ŸÑŸÉ ÿßŸÑŸÜÿ¥ÿ∑ŸäŸÜ Ÿàÿ∫Ÿäÿ± ÿßŸÑŸÜÿ¥ÿ∑ŸäŸÜ.',
          intent: 'customer_count_all',
          confidence: 0.9,
          usedPattern: false,
          adaptiveRecommendations: ['ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑÿπŸÖŸÑÿßÿ°', 'ÿ™ŸÇÿßÿ±Ÿäÿ± ÿßŸÑÿπŸÖŸÑÿßÿ°', 'ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿßŸÑÿπŸÖŸÑÿßÿ°']
        };
      } else if (normalizedQuery.includes('ŸÜÿ¥ÿ∑') || normalizedQuery.includes('ÿßŸÑŸÜÿ¥ÿ∑ŸäŸÜ')) {
        return {
          response: 'ÿ≥ÿ£ÿπÿ±ÿ∂ ŸÑŸÉ ÿßŸÑÿπŸÖŸÑÿßÿ° ÿßŸÑŸÜÿ¥ÿ∑ŸäŸÜ ŸÅŸÇÿ∑ ÿßŸÑÿ∞ŸäŸÜ ŸÑÿØŸäŸáŸÖ ÿ™ÿπÿßŸÖŸÑÿßÿ™ ÿ≠ÿßŸÑŸäÿ© ŸÖÿπ ÿßŸÑÿ¥ÿ±ŸÉÿ©.',
          intent: 'customer_count_active',
          confidence: 0.9,
          usedPattern: false,
          adaptiveRecommendations: ['ÿ™ŸÅÿßÿµŸäŸÑ ÿßŸÑÿπŸÖŸÑÿßÿ° ÿßŸÑŸÜÿ¥ÿ∑ŸäŸÜ', 'ÿ¢ÿÆÿ± ÿ™ÿπÿßŸÖŸÑÿßÿ™ ÿßŸÑÿπŸÖŸÑÿßÿ°', 'ÿπŸÇŸàÿØ ÿßŸÑÿπŸÖŸÑÿßÿ° ÿßŸÑŸÜÿ¥ÿ∑ÿ©']
        };
      }
    }
  }
  
  // Arabic keywords for contract/agreement counting
  const contractCountKeywords = ['ŸÉŸÖ ÿπŸÇÿØ', 'ŸÉŸÖ ÿßÿ™ŸÅÿßŸÇŸäÿ©', 'ÿπÿØÿØ ÿßŸÑÿπŸÇŸàÿØ', 'ÿπÿØÿØ ÿßŸÑÿßÿ™ŸÅÿßŸÇŸäÿßÿ™'];
  const customerCountKeywords = ['ŸÉŸÖ ÿπŸÖŸäŸÑ', 'ÿπÿØÿØ ÿßŸÑÿπŸÖŸÑÿßÿ°', 'ŸÉŸÖ ÿ≤ÿ®ŸàŸÜ'];
  
  // Check for simple count queries
  if (contractCountKeywords.some(keyword => normalizedQuery.includes(keyword))) {
    return {
      response: 'ŸÑŸÖÿ≥ÿßÿπÿØÿ™ŸÉ ŸÅŸä ŸÖÿπÿ±ŸÅÿ© ÿπÿØÿØ ÿßŸÑÿπŸÇŸàÿØÿå ÿ£ÿ≠ÿ™ÿßÿ¨ ŸÑŸÑŸàÿµŸàŸÑ ÿ•ŸÑŸâ ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™. ŸáŸÑ ÿ™ŸÇÿµÿØ ÿßŸÑÿπŸÇŸàÿØ ÿßŸÑŸÜÿ¥ÿ∑ÿ© ŸÅŸÇÿ∑ ÿ£ŸÖ ÿ¨ŸÖŸäÿπ ÿßŸÑÿπŸÇŸàÿØÿü',
      intent: 'contract_count_query',
      confidence: 0.9,
      usedPattern: false,
      adaptiveRecommendations: ['ÿπÿ±ÿ∂ ÿßŸÑÿπŸÇŸàÿØ ÿßŸÑŸÜÿ¥ÿ∑ÿ©', 'ÿπÿ±ÿ∂ ÿ¨ŸÖŸäÿπ ÿßŸÑÿπŸÇŸàÿØ', 'ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿßŸÑÿπŸÇŸàÿØ']
    };
  }
  
  if (customerCountKeywords.some(keyword => normalizedQuery.includes(keyword))) {
    return {
      response: 'ŸÑÿπÿ±ÿ∂ ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿßŸÑÿπŸÖŸÑÿßÿ°ÿå ŸáŸÑ ÿ™ÿ±ŸäÿØ ŸÖÿπÿ±ŸÅÿ© ÿßŸÑÿπŸÖŸÑÿßÿ° ÿßŸÑŸÜÿ¥ÿ∑ŸäŸÜ ÿ£ŸÖ ÿ¨ŸÖŸäÿπ ÿßŸÑÿπŸÖŸÑÿßÿ° ÿßŸÑŸÖÿ≥ÿ¨ŸÑŸäŸÜ ŸÅŸä ÿßŸÑŸÜÿ∏ÿßŸÖÿü',
      intent: 'customer_count_query',
      confidence: 0.9,
      usedPattern: false,
      adaptiveRecommendations: ['ÿπÿ±ÿ∂ ÿßŸÑÿπŸÖŸÑÿßÿ° ÿßŸÑŸÜÿ¥ÿ∑ŸäŸÜ', 'ÿπÿ±ÿ∂ ÿ¨ŸÖŸäÿπ ÿßŸÑÿπŸÖŸÑÿßÿ°', 'ÿ™ŸÇÿßÿ±Ÿäÿ± ÿßŸÑÿπŸÖŸÑÿßÿ°']
    };
  }

  // Fallback to AI processing for complex queries
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${openAIApiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'gpt-4o-mini',
      messages: [
        {
          role: 'system',
          content: `You are a helpful legal AI assistant. Provide helpful responses in Arabic for Arabic queries and English for English queries. 
          Be specific and actionable in your responses.`
        },
        {
          role: 'user',
          content: `Query: ${query}\nContext: ${JSON.stringify(context)}`
        }
      ],
      temperature: 0.7,
    }),
  });

  const data = await response.json();
  const responseText = data.choices[0].message.content;
  
  // Enhanced intent classification
  let intent = 'general_query';
  if (query.includes('ÿπŸÇÿØ') || query.includes('contract') || query.includes('ÿßÿ™ŸÅÿßŸÇŸäÿ©')) intent = 'contract_query';
  if (query.includes('ÿπŸÖŸäŸÑ') || query.includes('customer') || query.includes('ÿ≤ÿ®ŸàŸÜ')) intent = 'customer_query';
  if (query.includes('ŸÉŸÖ') || query.includes('ÿπÿØÿØ') || query.includes('count') || query.includes('how many')) intent = 'statistics_query';
  if (query.includes('ÿ®ÿ≠ÿ´') || query.includes('search') || query.includes('find')) intent = 'search_query';
  
  return {
    response: responseText,
    intent,
    confidence: 0.7, // Increased confidence for better processing
    usedPattern: false
  };
}

async function selfEvaluateAndLearn(
  supabaseClient: any,
  companyId: string,
  query: string,
  responseData: any,
  queryEmbedding: number[],
  processingType: string,
  userId: string
) {
  console.log('üéì Self-evaluating and learning from interaction...');
  
  try {
    // Always create learning patterns, even with low confidence
    const patternData = {
      query_embedding: queryEmbedding,
      response_quality: Math.max(0.6, responseData.confidence), // Minimum quality threshold
      processing_type: processingType,
      intent_detected: responseData.intent,
      confidence_level: responseData.confidence,
      context_features: extractContextFeatures(query),
      original_query: query,
      timestamp: new Date().toISOString()
    };

    // Check if similar pattern already exists
    const { data: existingPattern } = await supabaseClient
      .from('ai_learning_patterns')
      .select('*')
      .eq('company_id', companyId)
      .eq('pattern_type', responseData.intent)
      .single();

    if (existingPattern) {
      // Update existing pattern
      await supabaseClient
        .from('ai_learning_patterns')
        .update({
          usage_count: existingPattern.usage_count + 1,
          last_used_at: new Date().toISOString(),
          success_rate: Math.min(0.95, existingPattern.success_rate + 0.05) // Gradually improve
        })
        .eq('id', existingPattern.id);
      
      console.log('‚úÖ Updated existing learning pattern');
    } else {
      // Create new pattern
      await supabaseClient
        .from('ai_learning_patterns')
        .insert({
          company_id: companyId,
          pattern_type: responseData.intent,
          pattern_data: patternData,
          success_rate: Math.max(0.6, responseData.confidence), // Minimum success rate
          usage_count: 1,
          is_active: true
        });

      console.log('‚úÖ Created new learning pattern');
    }
  } catch (error) {
    console.error('Failed to create/update learning pattern:', error);
  }
}

function extractContextFeatures(query: string): any {
  return {
    length: query.length,
    language: query.match(/[\u0600-\u06FF]/) ? 'arabic' : 'english',
    hasNumbers: /\d/.test(query),
    hasQuestion: /\?|ŸÉŸÖ|ŸÖÿßÿ∞ÿß|ŸÉŸäŸÅ/.test(query),
    keywords: query.toLowerCase().split(' ').filter(word => word.length > 2)
  };
}

async function isQuerySimpleAndClear(query: string): Promise<boolean> {
  const normalizedQuery = query.toLowerCase().trim();
  
  // Define patterns for simple, clear queries
  const simplePatterns = [
    // Arabic patterns
    /ŸÉŸÖ\s+(ÿπŸÇÿØ|ÿßÿ™ŸÅÿßŸÇŸäÿ©|ÿπŸÖŸäŸÑ|ÿ≤ÿ®ŸàŸÜ)/,
    /ÿπÿØÿØ\s+(ÿßŸÑÿπŸÇŸàÿØ|ÿßŸÑÿßÿ™ŸÅÿßŸÇŸäÿßÿ™|ÿßŸÑÿπŸÖŸÑÿßÿ°)/,
    /ŸÖÿß\s+ÿπÿØÿØ/,
    /ÿ¨ŸÖŸäÿπ\s+(ÿßŸÑÿπŸÇŸàÿØ|ÿßŸÑÿßÿ™ŸÅÿßŸÇŸäÿßÿ™|ÿßŸÑÿπŸÖŸÑÿßÿ°)/,
    /ŸÉŸÑ\s+(ÿßŸÑÿπŸÇŸàÿØ|ÿßŸÑÿßÿ™ŸÅÿßŸÇŸäÿßÿ™|ÿßŸÑÿπŸÖŸÑÿßÿ°)/,
    /ŸÜÿ¥ÿ∑ÿ©ÿü?\s*(ŸÅŸÇÿ∑)?/,
    /ÿßŸÑŸÜÿ¥ÿ∑ÿ©\s*(ŸÅŸÇÿ∑)?/,
    
    // English patterns  
    /how\s+many\s+(contracts?|agreements?|customers?)/,
    /number\s+of\s+(contracts?|agreements?|customers?)/,
    /count\s+(contracts?|agreements?|customers?)/,
    /all\s+(contracts?|agreements?|customers?)/,
    /active\s+(contracts?|agreements?|customers?)/,
    
    // Status queries
    /ÿ≠ÿßŸÑÿ©\s+(ÿßŸÑÿπŸÇÿØ|ÿßŸÑÿßÿ™ŸÅÿßŸÇŸäÿ©)/,
    /status\s+of/,
    
    // Simple answers and confirmations
    /^(ŸÜÿπŸÖ|ŸÑÿß|yes|no)$/,
    /^(ÿ¨ŸÖŸäÿπ|ŸÉŸÑ|all)$/,
    /^(ÿßŸÑŸÜÿ¥ÿ∑ÿ©|active)$/
  ];
  
  // Also consider short responses (likely answers) as simple
  if (normalizedQuery.length < 20 && normalizedQuery.split(' ').length <= 3) {
    return true;
  }
  
  return simplePatterns.some(pattern => pattern.test(normalizedQuery));
}

function analyzeConversationContext(query: string, context: any) {
  const normalizedQuery = query.toLowerCase().trim();
  const conversationHistory = context?.conversationHistory || [];
  
  // Check if this looks like an answer to a previous question
  const isAnswerToQuestion = checkIfAnswerToQuestion(normalizedQuery, conversationHistory);
  
  // Calculate complexity and clarity scores
  const complexityScore = calculateComplexityScore(query);
  const clarityScore = calculateClarityScore(query);
  
  return {
    isAnswerToQuestion,
    complexityScore,
    clarityScore,
    conversationLength: conversationHistory.length,
    recentAIMessage: getLastAIMessage(conversationHistory)
  };
}

function checkIfAnswerToQuestion(query: string, conversationHistory: any[]): boolean {
  if (conversationHistory.length < 2) return false;
  
  // Get the last AI message
  const lastAIMessage = getLastAIMessage(conversationHistory);
  if (!lastAIMessage) return false;
  
  // Check if the last AI message was asking a question
  const wasQuestion = lastAIMessage.content.includes('?') || 
                     lastAIMessage.content.includes('ŸáŸÑ') ||
                     lastAIMessage.content.includes('ŸÖÿß') ||
                     lastAIMessage.content.includes('ŸÉŸÖ') ||
                     lastAIMessage.content.includes('ÿ£ŸäŸáŸÖÿß') ||
                     lastAIMessage.content.includes('ÿ£ÿ≠ÿ™ÿßÿ¨');
  
  if (!wasQuestion) return false;
  
  // Check if current query looks like an answer
  const answerPatterns = [
    /^(ÿ¨ŸÖŸäÿπ|ŸÉŸÑ|ÿßŸÑŸÜÿ¥ÿ∑ÿ©|ŸÜÿπŸÖ|ŸÑÿß|all|active|yes|no)/,
    /ÿßŸÑÿπŸÇŸàÿØ\s*(ÿßŸÑŸÜÿ¥ÿ∑ÿ©|ÿ¨ŸÖŸäÿπ)?/,
    /ÿßŸÑÿßÿ™ŸÅÿßŸÇŸäÿßÿ™\s*(ÿßŸÑŸÜÿ¥ÿ∑ÿ©|ÿ¨ŸÖŸäÿπ)?/,
    /ÿßŸÑÿπŸÖŸÑÿßÿ°\s*(ÿßŸÑŸÜÿ¥ÿ∑ŸäŸÜ|ÿ¨ŸÖŸäÿπ)?/
  ];
  
  return answerPatterns.some(pattern => pattern.test(query));
}

function getLastAIMessage(conversationHistory: any[]) {
  return conversationHistory
    .filter(msg => msg.type === 'ai')
    .slice(-1)[0];
}

function calculateComplexityScore(query: string): number {
  let score = 0;
  
  // Length factor
  if (query.length > 100) score += 0.3;
  else if (query.length > 50) score += 0.2;
  else if (query.length > 20) score += 0.1;
  
  // Word count factor
  const wordCount = query.split(' ').length;
  if (wordCount > 10) score += 0.3;
  else if (wordCount > 5) score += 0.2;
  
  // Complex keywords
  const complexKeywords = ['ÿ™ŸÅÿµŸäŸÑŸä', 'ÿ¥ÿßŸÖŸÑ', 'ÿ™ÿ≠ŸÑŸäŸÑ', 'ŸÖŸÇÿßÿ±ŸÜÿ©', 'comprehensive', 'detailed', 'analysis'];
  if (complexKeywords.some(keyword => query.includes(keyword))) score += 0.4;
  
  return Math.min(score, 1.0);
}

function calculateClarityScore(query: string): number {
  let score = 1.0;
  
  // Reduce score for vague words
  const vageWords = ['ÿ¥Ÿäÿ°', 'ÿ£ŸÖÿ±', 'ÿ≠ÿßÿ¨ÿ©', 'ŸÖŸàÿ∂Ÿàÿπ', 'thing', 'stuff', 'something'];
  if (vageWords.some(word => query.includes(word))) score -= 0.4;
  
  // Reduce score for questions without specific objects
  if (query.includes('ÿü') || query.includes('?')) {
    const hasSpecificObject = /ÿπŸÇÿØ|ÿßÿ™ŸÅÿßŸÇŸäÿ©|ÿπŸÖŸäŸÑ|ÿ≤ÿ®ŸàŸÜ|contract|agreement|customer/.test(query);
    if (!hasSpecificObject) score -= 0.3;
  }
  
  // Increase score for clear intent keywords
  const clearKeywords = ['ÿπÿØÿØ', 'ŸÉŸÖ', 'ŸÇÿßÿ¶ŸÖÿ©', 'count', 'list', 'show'];
  if (clearKeywords.some(keyword => query.includes(keyword))) score += 0.2;
  
  return Math.max(score, 0.0);
}

async function generateFollowUpSuggestions(query: string, responseData: any): Promise<string[]> {
  const suggestions = [];
  
  if (responseData.intent.includes('contract')) {
    suggestions.push('ÿπÿ±ÿ∂ ÿ™ŸÅÿßÿµŸäŸÑ ÿßŸÑÿπŸÇŸàÿØ', 'ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑÿπŸÇŸàÿØ ÿßŸÑŸÜÿ¥ÿ∑ÿ©', 'ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿßŸÑÿπŸÇŸàÿØ ÿßŸÑÿ¥Ÿáÿ±Ÿäÿ©');
  } else if (responseData.intent.includes('customer')) {
    suggestions.push('ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑÿπŸÖŸÑÿßÿ°', 'ÿ•ÿ∂ÿßŸÅÿ© ÿπŸÖŸäŸÑ ÿ¨ÿØŸäÿØ', 'ÿ™ŸÇÿßÿ±Ÿäÿ± ÿßŸÑÿπŸÖŸÑÿßÿ°');
  } else {
    suggestions.push('ÿßŸÑŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ', 'ÿßŸÑÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿ∞ÿßÿ™ ÿßŸÑÿµŸÑÿ©', 'ÿ™ÿµÿØŸäÿ± Ÿáÿ∞Ÿá ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™');
  }
  
  return suggestions;
}