# ============================================
# Test Generator Agent
# Auto-generates test skeletons for new files
# ============================================

name: üß™ Test Generator Agent

on:
  pull_request:
    paths:
      - 'src/**/*.ts'
      - 'src/**/*.tsx'
      - '!src/**/*.test.ts'
      - '!src/**/*.test.tsx'
      - '!src/**/*.spec.ts'
      - '!src/**/*.spec.tsx'

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}

jobs:
  generate-tests:
    name: üî¨ Test Coverage Check
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Get New Files
        id: new_files
        run: |
          # Get newly added files
          NEW_FILES=$(git diff --name-only --diff-filter=A ${{ github.event.pull_request.base.sha }} ${{ github.sha }} -- 'src/**/*.ts' 'src/**/*.tsx' | grep -v '.test.' | grep -v '.spec.' | tr '\n' ' ')
          echo "files=$NEW_FILES" >> $GITHUB_OUTPUT
          
          COUNT=$(echo "$NEW_FILES" | wc -w)
          echo "count=$COUNT" >> $GITHUB_OUTPUT

      - name: Check Test Coverage for New Files
        id: coverage
        run: |
          MISSING_TESTS=""
          MISSING_COUNT=0
          
          for file in ${{ steps.new_files.outputs.files }}; do
            if [ -n "$file" ] && [ -f "$file" ]; then
              # Get the base name without extension
              BASE="${file%.*}"
              DIR=$(dirname "$file")
              FILENAME=$(basename "$file" | sed 's/\.[^.]*$//')
              
              # Check for corresponding test file
              TEST_FILE_1="${BASE}.test.ts"
              TEST_FILE_2="${BASE}.test.tsx"
              TEST_FILE_3="${BASE}.spec.ts"
              TEST_FILE_4="${BASE}.spec.tsx"
              TEST_FILE_5="$DIR/__tests__/${FILENAME}.test.ts"
              TEST_FILE_6="$DIR/__tests__/${FILENAME}.test.tsx"
              
              HAS_TEST=false
              for test_file in "$TEST_FILE_1" "$TEST_FILE_2" "$TEST_FILE_3" "$TEST_FILE_4" "$TEST_FILE_5" "$TEST_FILE_6"; do
                if [ -f "$test_file" ]; then
                  HAS_TEST=true
                  break
                fi
              done
              
              if [[ "$HAS_TEST" == false ]]; then
                MISSING_TESTS="$MISSING_TESTS\n- $file"
                MISSING_COUNT=$((MISSING_COUNT + 1))
              fi
            fi
          done
          
          echo "missing_count=$MISSING_COUNT" >> $GITHUB_OUTPUT
          echo "missing_tests<<EOF" >> $GITHUB_OUTPUT
          echo -e "$MISSING_TESTS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          TOTAL=${{ steps.new_files.outputs.count }}
          if [[ "$TOTAL" -gt 0 ]]; then
            COVERAGE_PERCENT=$(( (TOTAL - MISSING_COUNT) * 100 / TOTAL ))
          else
            COVERAGE_PERCENT=100
          fi
          echo "coverage_percent=$COVERAGE_PERCENT" >> $GITHUB_OUTPUT
          
          if [[ "$COVERAGE_PERCENT" -lt 85 ]]; then
            echo "status=fail" >> $GITHUB_OUTPUT
          else
            echo "status=pass" >> $GITHUB_OUTPUT
          fi

      - name: Generate Test Skeletons
        id: generate
        if: steps.coverage.outputs.missing_count > 0
        run: |
          mkdir -p generated-tests
          
          for file in ${{ steps.new_files.outputs.files }}; do
            if [ -n "$file" ] && [ -f "$file" ]; then
              # Get base info
              BASE="${file%.*}"
              EXT="${file##*.}"
              FILENAME=$(basename "$file" | sed 's/\.[^.]*$//')
              
              # Determine test file extension
              if [[ "$EXT" == "tsx" ]]; then
                TEST_EXT="test.tsx"
              else
                TEST_EXT="test.ts"
              fi
              
              TEST_FILE="${BASE}.${TEST_EXT}"
              
              # Skip if test already exists
              if [ -f "$TEST_FILE" ]; then
                continue
              fi
              
              # Analyze file content
              CONTENT=$(cat "$file")
              
              # Extract exports
              EXPORTS=$(grep -oE 'export (const|function|class|interface|type) \w+' "$file" | awk '{print $3}' | tr '\n' ' ' || true)
              DEFAULT_EXPORT=$(grep -oE 'export default \w+' "$file" | awk '{print $3}' || true)
              
              # Generate test skeleton
              if echo "$file" | grep -qE '.tsx$'; then
                # React component test
                cat > "generated-tests/$(basename $TEST_FILE)" << TESTEOF
import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import { describe, it, expect, vi, beforeEach } from 'vitest';
// Import the component
// import { ${EXPORTS:-ComponentName} } from './${FILENAME}';

describe('${FILENAME}', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  it('should render without crashing', () => {
    // TODO: Implement test
    // render(<${DEFAULT_EXPORT:-ComponentName} />);
    // expect(screen.getByRole('...')).toBeInTheDocument();
    expect(true).toBe(true);
  });

  it('should handle user interactions', async () => {
    // TODO: Implement interaction test
    // render(<${DEFAULT_EXPORT:-ComponentName} />);
    // fireEvent.click(screen.getByRole('button'));
    // await waitFor(() => {
    //   expect(screen.getByText('...')).toBeInTheDocument();
    // });
    expect(true).toBe(true);
  });

  it('should handle loading state', () => {
    // TODO: Implement loading state test
    expect(true).toBe(true);
  });

  it('should handle error state', () => {
    // TODO: Implement error state test
    expect(true).toBe(true);
  });
});
TESTEOF
              else
                # Utility/Service test
                cat > "generated-tests/$(basename $TEST_FILE)" << TESTEOF
import { describe, it, expect, vi, beforeEach } from 'vitest';
// Import the module
// import { ${EXPORTS:-functionName} } from './${FILENAME}';

describe('${FILENAME}', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  describe('exported functions', () => {
    it('should exist', () => {
      // TODO: Verify exports
      expect(true).toBe(true);
    });

    // Add tests for each exported function:
    // ${EXPORTS}
  });

  it('should handle edge cases', () => {
    // TODO: Add edge case tests
    expect(true).toBe(true);
  });

  it('should handle errors gracefully', () => {
    // TODO: Add error handling tests
    expect(true).toBe(true);
  });
});
TESTEOF
              fi
            fi
          done
          
          GENERATED=$(ls generated-tests/ 2>/dev/null | wc -l)
          echo "generated_count=$GENERATED" >> $GITHUB_OUTPUT

      - name: Upload Generated Tests
        if: steps.generate.outputs.generated_count > 0
        uses: actions/upload-artifact@v4
        with:
          name: generated-test-skeletons
          path: generated-tests/
          retention-days: 7

      - name: Log to Supabase
        if: always()
        run: |
          curl -X POST "${{ env.SUPABASE_URL }}/rest/v1/cto_agent_audit" \
            -H "apikey: ${{ env.SUPABASE_SERVICE_ROLE_KEY }}" \
            -H "Authorization: Bearer ${{ env.SUPABASE_SERVICE_ROLE_KEY }}" \
            -H "Content-Type: application/json" \
            -H "Prefer: return=minimal" \
            -d '{
              "run_id": "${{ github.run_id }}",
              "stage": "test_coverage",
              "status": "${{ steps.coverage.outputs.status }}",
              "severity": "${{ steps.coverage.outputs.status == 'fail' && 'warning' || 'info' }}",
              "actor": "${{ github.actor }}",
              "pr_number": ${{ github.event.pull_request.number }},
              "branch": "${{ github.head_ref }}",
              "commit_sha": "${{ github.sha }}",
              "details": {
                "new_files": ${{ steps.new_files.outputs.count }},
                "missing_tests": ${{ steps.coverage.outputs.missing_count }},
                "coverage_percent": ${{ steps.coverage.outputs.coverage_percent }},
                "generated_skeletons": ${{ steps.generate.outputs.generated_count || 0 }}
              }
            }'

      - name: Comment on PR
        uses: actions/github-script@v7
        with:
          script: |
            const missingCount = '${{ steps.coverage.outputs.missing_count }}';
            const coveragePercent = '${{ steps.coverage.outputs.coverage_percent }}';
            const missingTests = `${{ steps.coverage.outputs.missing_tests }}`;
            const generatedCount = '${{ steps.generate.outputs.generated_count }}' || '0';
            
            let emoji = coveragePercent >= 85 ? '‚úÖ' : '‚ö†Ô∏è';
            let body = `## ${emoji} Test Coverage Report\n\n`;
            
            body += `**New File Test Coverage: ${coveragePercent}%**\n\n`;
            
            if (missingCount > 0) {
              body += `### üìù Files Missing Tests\n${missingTests}\n\n`;
              body += `> üí° Test skeletons have been generated and are available as artifacts.\n`;
              body += `> Download them from the Actions tab and add them to your PR.\n\n`;
              
              if (coveragePercent < 85) {
                body += `> ‚ö†Ô∏è **Minimum 85% test coverage required for new files.**\n`;
              }
            } else {
              body += `‚ú® All new files have corresponding tests!\n`;
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

